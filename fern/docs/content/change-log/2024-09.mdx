---
title: Changelog | September, 2024
---

## Improved Latency Filter and Sorting for Workflow Executions

_September 23rd, 2024_

You can now sort and filter by the Latency field in the Workflow Executions Table! This update allows for better prioritization and
identification of executions with higher or lower latencies, as well as targeting executions within a range of latencies.
We believe these improvements will greatly aid in monitoring and managing workflow executions and their performance and metrics!

## Improved Debugging for Map Nodes

_September 23rd, 2024_

It used to be difficult to debug problematic iterations when a Map Node failed. We now keep track of each iteration's execution and make it easy to view them. You can page through a Map Node's iterations one-by-one.

![Map Node Rejected Pagination](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-09/map-node-rejected-pagination.png)

Each of these iterations, included the any that failed, are now also show in a Map Node's full screen editor.

![Map Node Rejected Editor](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-09/map-node-rejected-editor.png)

The full screen editor now also allows you to cycle through each of an executed Map Node's iterations, making it easy to debug problematic iterations and iterate on the subworkflow used to produce that iteration's execution.

## Resizable Node Editor Panel

_September 20th, 2024_

For those of you using the new Workflow Builder, you'll now be able to resize the Node Editor Panel. This update makes it much easier to edit complex Conditional Node rules, Chat History Messages, JSON values, and more.

![Resizable editor panel](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-09/ResizableSidePanel.gif)

## Evaluations Performance Improvements

_September 17th, 2024_

While not as flashy as some of our other updates, we've undergone a major overhaul of our Evaluations backend resulting
in significant performance improvements to the Evaluations page. Test Suites consisting of thousands of Test Cases
used to feel sluggish and sometimes not load, but now load successfully and should feel much more responsive.

## Cost Tracking for Prompt Deployment Executions Table

_September 17th, 2024_

You can now see the cost of each Prompt Execution in the Prompt Executions Table.

![Cost tracking prompt executions](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-09/prompt_executions_cost_tracking.png)

This is the next step of many we have planned for improving visibility into LLM costs in Vellum. You might use this to audit expensive calls and optimize your prompts to reduce costs.

## Optimized Prompt Deployment Executions Table

_September 13th, 2024_

This update brings a reduction in load times for filters and sorts; in some instances, dropping 2 minute load times to a
few seconds.

We've achieved this by switching to a more efficient data source, enabling more effective filtering and sorting
capabilities. You'll notice faster page load times across the board, resulting in a smoother, more responsive experience
when working with Prompt Deployment Executions.

This optimization sets the stage for exciting new features we have in the works. Stay tuned for more updates that
will enhance your ability to analyze, and optimize your prompt executions.

## External ID Filtering for Workflow Deployment Executions

_September 13th, 2024_

Previously, when filtering workflow deployment executions by external IDs, you had to provide the exact string match
to retrieve relevant results.

Now, you can filter external IDs using a variety of string patterns. You can specify that the external ID
should start with, end with, or contain certain substrings. This enhancement allows for more flexible filtering,
making it easier to locate specific workflow deployment executions based on partial matches.

![new_external_id_filter_options](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-09/new_workflow_deployment_execution_external_id_filter_options.png)

## Workflow Execution Timeline View Revamp

_September 13th, 2024_

We have given the Workflow Execution Timeline View a bit of a facelift. Along with a more modern look, we have added a couple quality of life improvements:

- **Subworkflows**: Instead of needing to navigate to a separate page, you can now expand subworkflows to view their executions details within the same page.
- **Node Pages**: Instead of cluttering the page with the details of all nodes at once, we now display the details for just one node at a time. Click on a node to view its inputs, outputs, and more. Each node has its own permalink so that you can share the url with others.

![Workflow Execution Timeline](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-09/workflow-execution-timeline.png)

## OpenAI Strawberry (o1) Models

_September 12th, 2024_

OpenAI's newest [Strawberry (o1) models](https://openai.com/o1/) `o1-preview`, `o1-mini`, `o1-preview-2024-09-12`, & `o1-mini-2024-09-12` are now available in Vellum and have been added to all workspaces!

## Interactive Pages in Single Editor Mode

_September 7th, 2024_

It used to be that when two people were on the same Prompt/Workflow Sandbox, only one person could edit and interact with the page.
If you were a Viewer, you were unable to interact with the page at all and were blocked with a big page overlay.

Now, the page overlay is gone and Viewers can interact with the page in a read-only mode and perform actions that
don't affect the state of the page. This includes things like scrolling, opening modals, copying text, etc.

## Expand Cost in Execute Prompt APIs

_September 4th, 2024_

You can now opt in to receive the cost of a Prompt's execution in the response of the [Execute Prompt](/api-reference/prompts/execute-prompt#request.body.expand_meta.cost) and
[Execute Prompt Stream](/api-reference/prompts/execute-prompt-stream#request.body.expand_meta.cost) APIs.

This is helpful if you want to capture the cost of executing a Prompt in your own system or if you want to provide cost
transparency to your end users.

To opt in, you can pass the `expand_meta` field in the request body with the `cost` key set to `true`.

```json
{
  ...,
  "expand_meta" : {
    "cost": true
  }
}
```

You can expect a corresponding value to be included in the meta field on the response:

```json
{
  ...,
  "meta": {
    "cost" : {
        "value" : 0.000450003,
        "unit" : "USD"
    }
  }
}
```

This functionality is available in our SDKs beginning v0.8.9.

## Default Block Type Preference

_September 4th, 2024_

You can now set a default Block type to use when defining Prompts in Vellum. Whenever you see the "Add Block" or "Add Message" options in a Prompt Editor, your preferred Block type will be used.

By default, the Block type is set to "Rich Text," the newer option that supports Variable Chips. You can still switch between Block types for individual Blocks within the Prompt Editor.

![default block type toggle](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-09/default-block-type-toggle.png)

## New and Improved Code Editor

_September 3rd, 2024_

We now use [Monaco Editor](https://microsoft.github.io/monaco-editor/) for our code editor that is used by Workflow Code Nodes and custom Code Evaluation Metrics.
Monaco is the same editor that Visual Studio Code uses under the hood.

This offers a number of improvements including IntelliSense, semantic validation and syntax validation. Additionally we now inject Vellum Value types into the editor,
so you can now have fully typed input values for things such as Chat History. Some of these improvements are currently only available for TypeScript and not Python.

<iframe
  src='https://www.loom.com/embed/5b72b48a8e1643b69199e220f46e6bed?sid=11157905-c1f1-4b5d-974f-55229207663f'
  width='100%'
  height='450px'
></iframe>

## VPC Disable gVisor Option for Code Execution

_September 3rd, 2024_

VPC customers of Vellum can now disable gVisor sandboxing for code execution in self-hosted environments to significantly improve the performance of Code Nodes in Workflows.
gVisor is needed for secure sandboxing in our Managed SASS platform, but in a self hosted environment where you're the only organization,
it's not strictly required if you trust that users within your org won't run malicious code.

![gVisor self hosted flag](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-09/gvisor-flag.png)

## Download Original Document from UI

_September 2nd, 2024_

You can now download a file that was originally uploaded as a Document to a Document Index from the UI.
You'll find a new "Download Original" option in a Document's ••• More Menu.

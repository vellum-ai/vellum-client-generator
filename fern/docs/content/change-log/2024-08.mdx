---
title: Changelog | August, 2024
---

## GPT-4o Finetuning

_August 19th, 2024_

OpenAI's newest GPT-4o models `gpt-4o-2024-08-06` and `gpt-4o-mini-2024-07-18` are now available as base models to add as OpenAI finetuned models. 


## Workflow Execution Replay & Scrubbing

_August 18th, 2024_

You can now replay and scrub through the execution of a Workflow in Workflow Sandbox and Deployment Execution Details pages.
This feature is particularly useful for debugging and understanding the flow of your Workflow, especially if it
contains loops where a single node might be run more than once.

![Workflow Execution Replay & Scrubbing](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-08/workflow-execution-replay-and-scrubbing.gif)


## OpenAI Structured Outputs Support

_August 15th, 2024_

OpenAI released some API changes that allow their newest models to support [Structured Outputs](https://openai.com/index/introducing-structured-outputs-in-the-api/). This powerful new feature
enables developers to strictly define the expected JSON object schemas from the model as part of the response through a model parameter, or through a function call. This new functionality is now natively integrated within Vellum!

To use within the context of Function Calling, simply toggle on the `Strict` checkbox for any given Function Call:

![Function Call Strict](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-08/function-call-strict.png)

To enable Structured Outputs as part of a general OpenAI response, configure the `JSON Schema` setting as part of model parameters:

![JSON Schema Strict](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-08/json-schema-strict.png)

Both places come with upload/download functionality built into the form. Note that for function calling, this means we've reduced the scope of the upload/download to be _just_ the `Parameters`
JSON schema field. This allows schemas to be cross-compatible between either location since we are working with an [open specification](https://json-schema.org/understanding-json-schema).

![JSON Schema Strict](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-08/upload-download-schema.png)

## Native JSON Input Variable Support for Prompts

_August 14th, 2024_

Vellum Prompts have historically been able to accept strings and chat histories as dynamic inputs to their template.
If you wanted to operate on JSON, you'd have to pass it as a string and then parse it within the Prompt itself
(i.e. perform `json.loads()` within a Jinja Block).

Vellum Prompts now support native JSON as inputs! When you add an input variable to a Prompt, you can now select the new "JSON" type.

![JSON Variables Dropdown](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-08/json-variable-dropdown.png)

JSON input values will render as prettified JSON objects when referenced in Rich Text Blocks and can be operated on directly
without the need for `json.loads()` when referenced in Jinja Blocks.


## Workflow Deployment Executions Filtered to Just API Executions

_August 12th, 2024_

Our Workflow Deployment Executions page used to list all executions of a Workflow Deployment, no matter where they were invoked from. However, this
would often get confusing because you'd see a mix of results from both eval runs and production traffic in the same view.

Our Workflow Deployment Executions page now filters down to just those executions that were invoked via the API. Executions from evaluations are still accessible from within the Evaluations UI by hovering over a row and clicking the "View Workflow Details" button:

![View Workflow Details](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-08/view-workflow-details.png)

## Add Specific Releases to Evaluation Reports

_August 12th, 2024_

We've updated Evaluation Reports to give you more control over the releases you evaluate. Previously, you could only add the latest release of a Deployment to your reports. Now, you can select specific releases by their tag, allowing you to compare different versions within your Evaluation Reports.

![Add Deployment](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-08/evaluation-report-add-by-release-tag.png)

## Workflow Sandbox Latency

_August 9th, 2024_

You can now view the latency of Workflow Sandboxes and their Nodes. To enable viewing latency click the Workflow Sandbox settings gear icon in the top right and turn on the "View Latency" option.

![Workflow Sandbox Latency](https://storage.cloud.google.com/vellum-public/help-docs/changelogs/2024-08/workflow-latency-1.png)
![Workflow Sandbox Latency Settings](https://storage.cloud.google.com/vellum-public/help-docs/changelogs/2024-08/workflow-latency-2.png)

## Prompt Sandbox Cost Tracking

_August 9th, 2024_

You can now see the dollar cost of a Prompt's execution within both a Prompt Sandbox's Prompt Editor and Comparison Mode views.
These costs are calculated using model providers' publicly available pricing data in conjunction with the number of input/output tokens used.

![Prompt Sandbox With Cost Tracking](https://storage.cloud.google.com/vellum-public/help-docs/changelogs/2024-08/prompt_sandbox_with_cost_tracking.png)
![Prompt Sandbox Comparison With Cost Tracking](https://storage.cloud.google.com/vellum-public/help-docs/changelogs/2024-08/prompt_sandbox_comparison_with_cost_tracking.png)

If you're curious about a given model's pricing, you can view details in the Model's detail page.
![MLModel Detail Page with Billing Config](https://storage.cloud.google.com/vellum-public/help-docs/changelogs/2024-08/mlmodel_detail_page_with_cost_config.png)
Most popular models already have pricing information populated, with support for even more models following in the coming days.
Showing cost information in Prompt Sandboxes is just the first step! We'll expose cost details throughout more of Vellum over time.

## GPT-4o 2024-08-06

_August 6th, 2024_

OpenAI's newest GPT-4o model `gpt-4o-2024-08-06` is now available in Vellum and has been added to all workspaces!

## Deployment Descriptions

_August 2nd, 2024_

You can now update your Prompt and Workflow Deployments to include a human-readable description. This is useful for giving other members of your team a high-level summary
of what the Prompt or Workflow does without needing to parse through the configuration or control flow.

![Update Deployment Description](https://storage.cloud.google.com/vellum-public/help-docs/changelogs/2024-08/update-deployment-description.png)

Once set, the description will appear as part of the Deployment Details page within the Deployment Info section:

![Display Deployment Description](https://storage.cloud.google.com/vellum-public/help-docs/changelogs/2024-08/display-deployment-description.png)

## Evaluation Report History

_August 1st, 2024_

It used to be that you could only view the latest set of Evaluation results for a given Prompt or Workflow. But now,
you can view a history of all Evaluation runs and go back to view the results of any prior state.

![Evaluation Report History](https://storage.cloud.google.com/vellum-public/help-docs/changelogs/2024-08/evaluation-report-history.png)

This is particularly helpful if you want to do things like compare the results of two different Evaluation runs,
download the results of a past Evaluation run, or simply view the Test Cases that existed at that time.

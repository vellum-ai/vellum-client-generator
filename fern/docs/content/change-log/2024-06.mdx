---
title: Changelog | June, 2024
---

## Map Nodes
_June 27th, 2024_

Often times when designing a workflow you need to iterate over an array and run the same operation on each item.
Previously this was only accomplishable by [manually creating the loop](https://docs.vellum.ai/help-center/workflows/common-architectures#3-calling-a-prompt-for-each-item-in-an-array) by connecting Nodes in a tedious layout.

To make this process easier, we are now introducing Map Nodes! Map Nodes work in the same way that array map functions do in many common programming languages.
The Nodes take a JSON array as an input and iterate over it, running a Subworkflow for each item. The output of every Subworkflow is then combined into a single array as a Node output.
Map Nodes also support up to 12 concurrent iterations.

<iframe
  src="https://www.loom.com/embed/59a1132879104063b3bf3641706f6128"
  width="100%"
  height="450px"
></iframe>

## Inline Subworkflow Nodes

_June 26th, 2024_

Subworkflow nodes are a powerful node within Vellum Workflows that allow users to create reusable units of node logic. However up until now, they necessitated
developing the Workflow in a separate Sandbox, and for that Workflow to be deployed in order to reference it in a particular Workflow.

Today, we are releasing Inline Subworkflows! They empower users to create and group together modular units of nodes directly within the context of an existing
Workflow. The node spawns its own editor and supports similar UX as the parent Workflow such as all existing nodes and copy/paste.

![](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/inline-subworkflow-editor.png)

For more details, check out our [new help center doc](/help-center/workflows/experimentation#inline-subworkflow-node).

## Claude 3.5 Sonnet Support

_June 20th, 2024_

We now support the new [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) model. It has already been automatically added to all workspaces.

We also support the model hosted through AWS Bedrock. You can add it to your workspace from the [models page](https://app.vellum.ai/models).

## Workflow Notes

_June 13th, 2024_

To help you organize and document your Workflows we've added Workflow Notes with customizable colors and font sizes. You can find Workflow Notes in the Workflow Nodes drag and drop selector.

![Workflow Notes](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/note-node.png)

## Workflow Node Comments

_June 13th, 2024_

You can now add a comment to any Workflow Node to help you document your Workflow's logic. To add a comment click the chat bubble icon on the top right of the Node to open up the comment section.

![Node Comments](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/node-comments.png)

## Breadcrumb Context Menus

_June 11th, 2024_

You'll now see breadcrumbs that show the folder path whenever visiting the details of an entity in Vellum. This is helpful for seeing the file structure and easily navigating up to a parent folder.

With this, you can also rename a parent folder by right-clicking on its breadcrumb rather than having to first navigate to its parent.

Lastly, can also now access all of an entity's "More Menu" options by right-clicking its card when on the entity's grid view.

![Breadcrumb Context Menus](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/breadcrumb-context-menus.png)

## Override Vellum Provided API Keys

_June 10th, 2024_

You can now provide your own API keys for models that Vellum provides API keys for such as Fireworks hosted models. To do so, click the 3 dot menu on a Model card and click the "Set API Key" option.

![API Key Override](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/api-key-override.png)

## Undo and Redo for Workflow Sandboxes

_June 7th, 2024_

Made a mistake while editing a workflow you want to undo? Good news, you can now undo and redo from within Workflow Sandboxes by using keyboard shortcuts or by clicking the new undo and redo buttons.

![Workflow Undo Redo](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/undo-redo.gif)

## Support for Multiple Outputs in Workflow Metrics

_June 7th, 2024_

Using Vellum Workflows to power custom LLM metrics (i.e. have one AI grade another AI) is super powerful, but to date,
you've only been able to use Workflows that produce a single `score` output.

We now have official support for Workflow Evaluators that produce multiple outputs! As long as the Workflow used as
your Metric has at least one Final Output Node of type `NUMBER` named `score`, you can add as many additional Final Output Nodes
with custom names and types as you like.

All outputs are shown when the Metric is used in an Evaluation Report.

![Workflow Sandbox and Variant IDs](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/multiple-outputs-in-metrics.png)

Note: only the `score` output is aggregated and shown in the aggregate view.

## API for Updating a Test Suite's Test Cases in Bulk

_June 6th, 2024_

For a while now you've been able to programmatically [upsert](/api-reference/api-reference/test-suites/upsert-test-suite-test-case)
and [delete](/api-reference/api-reference/test-suites/delete-test-suite-test-case) Test Cases in a Test suite individually.

However, this can be problematic if you want to operate on many Test Cases at once. To solve this, we've added an API to create, replace, and delete Test Cases in bulk.

Check out the new Bulk Test Case Operations API in our docs [here](/api-reference/api-reference/test-suites/test-suite-test-cases-bulk).

Note: this API is available in our SDKs beginning version 0.6.4.

## APIs for Programmatically Moving Release Tags

_June 5th, 2024_

To follow up the release of APIs for [programmatically deploying Prompts and Workflows](/changelog/2024/2024-06#apis-for-programmatically-deploying-promptsworkflows),
we're excited to also announce APIs for programmatically moving [Release Tags](/help-center/deployments/managing-releases#introduction-to-deployment-release-tags).

With these APIs, you can create a CI/CD pipeline that automatically moves a Release Tag for one environment from one version of a Prompt/Workflow to another.
For example, you might run certain tests or QA processes before promoting `STAGING` to `PRODUCTION`.

To move a Prompt Deployment Release Tag, check out the API docs [here](/api-reference/api-reference/deployments/update-deployment-release-tag).

To move a Workflow Deployment Release Tag, see the API docs [here](/api-reference/api-reference/workflow-deployments/update-workflow-release-tag).

Note: these APIs are available in our SDKs beginning version 0.6.3.

## APIs for Programmatically Deploying Prompts/Workflows

_June 5th, 2024_

Thanks to the desires of a few very forward-thinking customers, we now have APIs to support programmatically deploying prompts and workflows.
These APIs can be used as the basis for CI/CD pipelines for Vellum-managed entities.

We're super bullish on integrating Vellum with existing release management systems (think, Github Actions) and you can expect
to see more from us here, soon!

To deploy a Prompt, you'll need the IDs of the Prompt Sandbox and the Prompt Variant shown here:

![Prompt Sandbox and Variant IDs](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/prompt-sandbox-ids.png)

And can then hit the Deploy Prompt endpoint found [here](/api-reference/api-reference/sandboxes/deploy-prompt).

Similarly, to deploy a Workflow, you'll need the IDs of the Workflow Sandbox and the Workflow shown here:

![Workflow Sandbox and Variant IDs](https://storage.googleapis.com/vellum-public/help-docs/changelogs/2024-06/workflow-sandbox-ids.png)

And can then hit the Deploy Workflow endpoint found [here](/api-reference/api-reference/workflow-sandboxes/deploy-workflow).

Note: these APIs are available in our SDKs beginning version 0.6.3.

## Image Support in Claude 3 and Gemini Models

_June 3rd, 2024_

Until now, GPT-4 was the only multi-modal family of models supported in Vellum that let you parse images and return text.

Vellum now also supports multi-modality for Claude 3 and Gemini models. This means you can now use Vellum's prompt comparison UI and normalized API layer to compare and easily swap between multi-modal models.

This is particularly useful if you're trying to extract text from images, classify pictures, and more, and need to find the best model for your specific use-case.

For more on how to work with images in Vellum, see our [help docs here](/help-center/prompts/images).

---
title: Changelog | February, 2024
description: Discover the newest features and improvements in Vellum's product update for February.
---

## Add Entity to Folder API

_February 29th, 2024_

We've exposed a new API endpoint to add an existing entity to an existing folder. This is useful if you want to programmatically organize your entities in Vellum. You can find the new endpoint and details on how to invoke it in our [API documentation](https://docs.vellum.ai/api-reference/api-reference/folder-entities/add-entity-to-folder).


## Vellum is SOC 2 Type 2 Compliant

_February 28th, 2024_

Vellum is now SOC 2 Type 2 compliant! This means that an independent auditor has verified that Vellum's information security practices, policies, and procedures meet the SOC 2 standards for security, availability, processing integrity, confidentiality, and privacy.
If you'd like to learn more about Vellum's security practices or request a copy of our SOC 2 report, please reach out to us at [security@vellum.ai](mailto:security@vellum.ai).


## Save Workflow Execution from Details Page

_February 23rd, 2024_

Previously you were able to save your workflow execution to a test suite or sandbox scenario from the executions table. Now you can do the same from each execution's details page! Both the "Save As Test Case" and "Save As Scenario" buttons should now appear on the top right of the execution:

![Save Workflow Execution Details](https://storage.googleapis.com/vellum-public/help-docs/save_workflow_execution_detail.png)

## Workflow Builder UI Settings

_February 21st, 2024_

Have you ever wanted to pan around workflows using the W-A-S-D keys? Looking for more control over your screen real estate?

Good news! You can now adjust these settings and more in the new workflow UI settings! Access the settings by clicking the new gear icon in the top right of your workflow builder.

![Workflow Builder Settings](https://storage.googleapis.com/vellum-public/help-docs/workflow-settings.png)

## Custom Release Tags

_February 21st, 2024_

You can now manage your Prompt and Workflow release process with greater flexibility and control using Custom Release Tags! Pin your Vellum API requests to tags you define for a given Prompt/Workflow Deployment. These tags can be easily re-assigned within the Vellum app so you can update your production, staging or other custom environment to point to a new version of a prompt or workflow â€” all without making any code changes!

Going forward, new customers of Vellum will no longer see the legacy "Environment" tags in Vellum's UI. Custom Release Tags are the new, first-class mechanism for managing different releases of the same prompt/workflow in Vellum. We will slowly be deprecating and removing the legacy "Environment" tags for existing customers.

Learn more about Managing Releases in our [Help Center article](http://docs.vellum.ai/help-center/deployments/managing-releases) or watch the video walkthrough below:

<iframe
  src="https://www.loom.com/embed/56992fb51372400ebdb69228c0b53b5d"
  width="100%"
  height="450px"
></iframe>

## Better Function Call Display

_February 15th, 2024_

We've beautified the display of model function calls in both prompt sandboxes and workflow prompt nodes! Say goodbye to the hard to read and mundane JSON strings.
![Fireworks Function Call Model](https://storage.googleapis.com/vellum-public/help-docs/function-call-display.png)

## Evaluation Reports

_February 12th, 2024_

Test Suite Runs have received a big upgrade, and now live in its own tab - Evaluations. You are now able to compare a Prompt or Workflow Variant against a Deployment, and view aggregate Metrics like Median or P90.

See a demo of the complete set of updates here:

<iframe
  src="https://www.loom.com/embed/c81360d2736746cfbf90c6ebfae82637"
  width="100%"
  height="450px"
></iframe>

## Fireworks Function Calling Model

_February 5nd, 2024_

OpenAI's GPT models have traditionally led the way in supporting structured data generation through function calling. But late last year Fireworks AI splashed in with their own [function calling model](https://fireworks.ai/blog/fireworks-raises-the-quality-bar-with-function-calling-model-and-api-release)! This model is now available in Vellum for those interested in an open source alternative to GPT.
![Fireworks Function Call Model](https://storage.googleapis.com/vellum-public/help-docs/fireworks-function-call.png)

---

## Cloning Workflow Nodes

_February 2nd, 2024_

When you hover over any node in your Workflow editor, you will see a new `Duplicate Node` icon. Clicking on this will create a new copy of a node! Never again will you need to start a node from scratch when you want to just tweak a field or two.

![Clone Nodes](https://storage.googleapis.com/vellum-public/help-docs/clone-nodes.png)

---

## Prompt Node Retries

_February 1st, 2024_

You can now detect when a Prompt Node within a Workflow errors by using a Conditional Node. Using this, you can now build out retry logic around Prompt Nodes within your Workflow! This is useful if you want to catch retryable errors (like rate limit errors from an LLM provider) and try making the call to the LLM again.

See a demo of it in action here:

<iframe
  src="https://www.loom.com/embed/770a1ac0bbaa4f9d9192d336eb0a191c"
  width="100%"
  height="450px"
></iframe>

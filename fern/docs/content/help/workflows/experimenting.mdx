## About Workflows

Workflows is a product in Vellum's LLM dev platform that helps you quickly prototype, deploy, and manage complex chains of LLM calls and the business logic that tie them together. We solve the "whack-a-mole" problem encountered by companies that use popular open source frameworks to build AI applications, but are scared to make changes for fear of introducing regressions in production.

The Workflows UI consists of a graphical app builder where you can string together various nodes and test various input values through this system. Each prompt can also be tested extensively through Playground & Test Suites. When implemented effectively, Workflows can help you build advanced LLM applications

## Supported Node Types, as of August 14, 2023

The names of nodes can be edited in-line once the node has been added to the UI. You can add as many nodes as you want to your Workflow. Since there is extreme flexibility in how Workflows can be created, you can modify your architecture to your desire by starting from these building blocks. Common architectures are shared in a separate help center doc ([Common Workflow Architectures](/help-center/documents/uploading-documents)) and will be updated over time.

![Workflow Nodes](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa6573716-a36b-4825-9cbe-1b6a42589c07%2FScreenshot_2023-08-14_at_5.16.16_PM.png?table=block&id=e5d716f5-bbd0-47fc-a70d-6ddd1cba2b89&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)

Drag and drop a node from the side panel into the UI and start building

### 1. Prompt Nodes

A core part of any LLM application. This node represents a call to a Large Language Model. Similar to Vellum Prompts, you can use test out models from any of the major providers or open source community, including OpenAI, Anthropic, Cohere, Google, Mosaic, Falcon-40b & Llama-2.

Upon creating a Prompt Node you’ll be asked to import a prompt from an existing Deployment, Sandbox, or create one from scratch. Prompts are defined by their variables, prompt template, model provider, and parameters. Refer to this help center article to learn more about our prompt syntax ([Vellum Prompt Template Syntax](/help-center/prompts/prompt-engineering)).

![Prompt Node](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F176b032f-2e76-46b8-a512-98cda98e29e2%2FScreenshot_2023-08-14_at_6.31.37_PM.png?table=block&id=0276df15-be50-41cf-8275-702659cefe21&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)

### 2. Search Node

The Search Node returns results from a Document Index stored inside Vellum Search. Once your documents are uploaded in an index (details on how to do that here: [Uploading Documents](/help-center/documents/uploading-documents)), you can start using them in a Workflow.

The index in a Search Node can be fixed for the Workflow or chosen dynamically based on the output of an upstream node. Additional configuration options, similar to the ones in Vellum Search are also available in the Search Node.

![Search Node](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F851861cc-affb-43a3-a9b0-f929b6fea326%2FScreenshot_2023-08-14_at_6.31.04_PM.png?table=block&id=76b7b218-c27b-4fc6-8e77-016aa5d8934b&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)

### 3. Conditional Node

Conditional Nodes are extremely powerful because they can help you diverge the execution path of your Workflow based on the results of an upstream node. The Conditional Node supports as many if-else-if conditions as you’d like and the rules can be grouped / nested within each other.

The number of exit options from a conditional node equal the number of if-else-if conditions created on the node

![Conditional Node](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F90eb045f-b6d0-49ca-b9b4-9ea67b935ecf%2FScreenshot_2023-08-14_at_6.28.47_PM.png?table=block&id=6fc7ad3d-7b0e-4cdd-b1d6-18f97380c86b&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)

### 4. Merge Node

Merge Nodes are used when the goal is to bring back the execution of divergent paths into one path. You can configure the number of inputs to a Merge Node and choose between “Await All” or “Await Any” as your merge strategy. The merge strategy determines the logic that will continue workflow execution.

![Merge Node](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F53711911-290d-4343-b304-48cf02d8ed1f%2FScreenshot_2023-08-14_at_6.29.17_PM.png?table=block&id=79c5239c-55cd-438a-b359-69b123bf09af&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)

### 5. Final Output Node

The Final Output Node represents the end of your workflow. Your workflow may have multiple Final Output Nodes if the execution has been branched off from an upstream node.

A name for the output and an output type must be configured here because the response streamed back from the endpoint (when the workflow is taken to production) has this information included.

![Final Output Node](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2ccdf40f-979b-4d35-a349-d42b426d55bb%2FScreenshot_2023-08-14_at_6.38.47_PM.png?table=block&id=d939b470-db14-4668-97c7-7603687f3ab5&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)

## Connecting Workflow Nodes and Defining Variables

Workflow nodes are connected by linking the output of one node to the input of another node. For any node the variables can be populated either by the results of an upstream node or the values of global variables.

When 2 nodes are successfully connected there’s a solid purple line between the nodes and the connection points turn blue. Here’s an example of a workflow that’s connected successfully:

![Connecting Workflow Nodes and Defining Variables](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F56832755-3b13-4199-a4aa-7f8786bbd467%2FScreenshot_2023-08-14_at_6.56.46_PM.png?table=block&id=39b07270-b779-48dd-905f-52a77374e7b3&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)

## Running a Workflow

Each variable in a node can either take the value of an upstream node or the value can be defined globally. To define them globally, you can populate them in the Input Variables dropdown before running a workflow. You can define as many scenarios as you want, each scenario is a unique set of input values that will be sent to the workflow.

Variables can be added one-by-one using the Add button or automatically using Auto-Add. Auto-Add looks at all the variables in the workflow and adds them to the scenario.

![Workflow Inputs](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F7cfe8f7f-728e-492a-a593-20ea88cb37ba%2FScreenshot_2023-08-14_at_6.58.31_PM.png?table=block&id=a1c8f43a-4c07-4101-bb2b-e50ae5aad5b8&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)

Once all the variables are selected for each prompt (either as values of upstream nodes or defined globally), you are now ready to Run your workflow!

When you Run the Workflow (purple button on the top right corner), you will see the execution path of the Workflow in green and the intermediate results at each step of the workflow. If the results at the end of the Workflow look surprising then may be a good idea to check what the responses look like at each step.

Here’s an example of a workflow that’s executed successfully:

![Executed Workflow](https://vellum-ai.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4e0d938e-d543-438d-bef7-2e666655e86d%2Fworkflows-sneak-peak_(2).png?table=block&id=e2cc252e-dd92-4aa7-a89b-ca1ebb204bb9&spaceId=71c05e3e-272b-4acf-9889-90a304d95d06&width=1770&userId=&cache=v2)
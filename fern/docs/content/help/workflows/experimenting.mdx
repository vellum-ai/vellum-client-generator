---
title: Streamline AI App Development with Vellum's Workflows
description: Discover how Vellum's Workflows simplifies building AI apps by managing complex LLM call chains and business logic easily.
---

## About Workflows

Workflows is a product in Vellum's LLM dev platform that helps you quickly prototype, deploy, and manage complex chains of LLM calls and the business logic that tie them together. We solve the "whack-a-mole" problem encountered by companies that use popular open source frameworks to build AI applications, but are scared to make changes for fear of introducing regressions in production.

The Workflows UI consists of a graphical app builder where you can string together various nodes and test various input values through this system. Each prompt can also be tested extensively through Playground & Test Suites. When implemented effectively, Workflows can help you build advanced LLM applications

## Supported Node Types

The names of nodes can be edited in-line once the node has been added to the UI. You can add as many nodes as you want to your Workflow. Since there is extreme flexibility in how Workflows can be created, you can modify your architecture to your desire by starting from these building blocks. Common architectures are shared in a separate help center doc ([Common Workflow Architectures](/help-center/documents/uploading-documents)) and will be updated over time.

![Workflow Nodes](https://storage.googleapis.com/vellum-public/help-docs/workflow_nodes.png)

Drag and drop a node from the side panel into the UI and start building

### Prompt Nodes

A core part of any LLM application. This node represents a call to a Large Language Model. Similar to Vellum Prompts, you can use test out models from any of the major providers or open source community, including OpenAI, Anthropic, Cohere, Google, Mosaic, Falcon-40b & Llama-2.

Upon creating a Prompt Node you’ll be asked to import a prompt from an existing Deployment, Sandbox, or create one from scratch. Prompts are defined by their variables, prompt template, model provider, and parameters. Refer to this help center article to learn more about our prompt syntax ([Vellum Prompt Template Syntax](/help-center/prompts/prompt-engineering)).

![Prompt Node](https://storage.googleapis.com/vellum-public/help-docs/prompt_node.png)


### Templating Nodes

The templating node allows you to perform custom data transformations on a set of defined inputs into a new output. You could use this to define constants, manipulate data before feeding into a prompt, or massage a response to a format to your liking.

Check out our [common data transformation templates](https://docs.vellum.ai/help-center/workflows/common-data-transforms) for some common examples.

![Templating Node](https://storage.googleapis.com/vellum-public/help-docs/templating-node.png)

### Search Node

The Search Node returns results from a Document Index stored inside Vellum Search. Once your documents are uploaded in an index (details on how to do that here: [Uploading Documents](/help-center/documents/uploading-documents)), you can start using them in a Workflow.

The index in a Search Node can be fixed for the Workflow or chosen dynamically based on the output of an upstream node. Additional configuration options, similar to the ones in Vellum Search are also available in the Search Node.

![Search Node](https://storage.googleapis.com/vellum-public/help-docs/search_node.png)

### API Node

The API node invokes an API endpoint and returns back the status code, raw output, and JSON output if applicable. These APIs could be either publically accessible or ones that are privately defined within your backend through the help of Authorization headers and Workspace Secrets. Simply define a URL, HTTP Method, and the body that you would like to send to the desired endpoint.

![API Node](https://storage.googleapis.com/vellum-public/help-docs/api-node.png)

### Code Execution Nodes

The code execution node empowers you to include custom logic defined directly in the workflow. You could even import custom public packages within the node's logic. We support the following languages:
- Python
- TypeScript

![Code Execution Node](https://storage.googleapis.com/vellum-public/help-docs/code-exec-node.png)

### Subworkflow Nodes

Subworkflow Nodes are essential for managing giant, complex workflows. Define reusable groups of workflow nodes in one sandbox and have it directly accessible upon deployment from any other workflow in your workspace. Subworkflow nodes also support release tag specification, allowing you the option to always invoke the latest workflow, or pinning to a specific release tag defined by you.

Check out the video below to see Subworkflow Nodes in action!

<iframe
  src="https://www.loom.com/embed/0232341e74854d09a6aa08c4a96b3af7"
  width="100%"
  height="450px"
></iframe>

### Conditional Node

Conditional Nodes are extremely powerful because they can help you diverge the execution path of your Workflow based on the results of an upstream node. The Conditional Node supports as many if-else-if conditions as you’d like and the rules can be grouped / nested within each other.

The number of exit options from a conditional node equal the number of if-else-if conditions created on the node

![Conditional Node](https://storage.googleapis.com/vellum-public/help-docs/conditional_node.png)

### Merge Node

Merge Nodes are used when the goal is to bring back the execution of divergent paths into one path. You can configure the number of inputs to a Merge Node and choose between “Await All” or “Await Any” as your merge strategy. The merge strategy determines the logic that will continue workflow execution.

![Merge Node](https://storage.googleapis.com/vellum-public/help-docs/merge_node.png)

### Final Output Node

The Final Output Node represents the end of your workflow. Your workflow may have multiple Final Output Nodes if the execution has been branched off from an upstream node.

A name for the output and an output type must be configured here because the response streamed back from the endpoint (when the workflow is taken to production) has this information included.

![Final Output Node](https://storage.googleapis.com/vellum-public/help-docs/terminal_node.png)

### Error Node

The Error Node enables you to reject the full workflow at any point whenever it gets invoked. There are two types of errors you could raise with this node:
- Pass-through - Use an `Error` output from an upstream node and pass it through to this node.
- Custom - Define your own `String` output that this node will use as an error message

![Error Node](https://storage.googleapis.com/vellum-public/help-docs/error-node.png)

## Connecting Workflow Nodes and Defining Variables

Workflow nodes are connected by linking the output of one node to the input of another node. For any node the variables can be populated either by the results of an upstream node or the values of global variables.

When 2 nodes are successfully connected there’s a solid purple line between the nodes and the connection points turn blue. Here’s an example of a workflow that’s connected successfully:

![Connecting Workflow Nodes and Defining Variables](https://storage.googleapis.com/vellum-public/help-docs/connected_nodes_and_edges.png)

## Running a Workflow

Each variable in a node can either take the value of an upstream node or the value can be defined globally. To define them globally, you can populate them in the Input Variables dropdown before running a workflow. You can define as many scenarios as you want, each scenario is a unique set of input values that will be sent to the workflow.

Variables can be added one-by-one using the Add button or automatically using Auto-Add. Auto-Add looks at all the variables in the workflow and adds them to the scenario.

![Workflow Inputs](https://storage.googleapis.com/vellum-public/help-docs/workflow_input_variable_values.png)

Once all the variables are selected for each prompt (either as values of upstream nodes or defined globally), you are now ready to Run your workflow!

When you Run the Workflow (purple button on the top right corner), you will see the execution path of the Workflow in green and the intermediate results at each step of the workflow. If the results at the end of the Workflow look surprising then may be a good idea to check what the responses look like at each step.

Here’s an example of a workflow that’s executed successfully:

![Executed Workflow](https://storage.googleapis.com/vellum-public/help-docs/executed_workflow.png)